---
title: "Analysis for 'Biased colour learning in Trinidadian guppies'"
output:
  bookdown::html_document2:
    include:
      highlight: pygments
    css: styles.css
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
      smooth_scroll: true
    number_sections: false
    split_by: section
    
knit: (function(input, ...) {
    rmarkdown::render(
      input,
      output_file = 'docs/analysis')
  })
---

<div class="topnav">
  <a href="index.html">Home</a>
  <a href="methods.html">Methods</a>
    <a class="active" href="analysis.html">Analysis</a>
    <a href="https://www.github.com/wyatt-toure">GitHub</a>
</div>

<p class="author-name">M. Wyatt Toure<span class="affil-mark">1*</span>, Simon M. Reader<span class="affil-mark">1</span></p>

<p class="author-affil"><span class="affil-mark">1</span>McGill University, Department of Biology, 1205 Docteur Penfield, Montreal, Quebec H3A 1B1, Canada</p>
<p><span class="affil-mark">*</span>Corresponding Author: <br>M. Wyatt Toure<br> e-mail: `m_wyatt.toure@mail.mcgill.ca`<br></p>

Date of last update: `r format(Sys.Date(), '%b %d %Y')`

***

```{r library-prep, include=FALSE}
library(lme4)
library(tidyr)
library(lmerTest)
library(ggplot2)
library(ggpubr)
library(DHARMa)
library(dplyr)
library(effects)
library(broom)
library(broom.mixed)
library(knitr)
library(emmeans)
library(report)
library(cowplot)
library(tidyext)
library(glmmTMB)
library(MASS)
```

```{r data-prep, include=FALSE}
#### Reading in Data 
my.data = read.csv('data/experiment-2-master-sheet-clean.csv')

# Crerating new variables 
my.data = my.data %>% group_by(id) %>% mutate(rewarding.object.preference = (time.with.trained.object-time.with.untrained.object))

my.data = my.data %>% group_by(id) %>% mutate(rewarding.object.preference.prop = (time.with.trained.object/(time.with.trained.object+time.with.untrained.object)))

my.data = my.data %>% mutate(green.object.preference = (case_when(
  rewarding.object.colour == "green" ~ (time.with.trained.object-time.with.untrained.object), 
  rewarding.object.colour == "blue" ~ (time.with.untrained.object-time.with.trained.object) 
)))

training.data = my.data %>% filter(trial.type =='training')

# Restrict data to only the baseline and re-test data

test.data = my.data %>% filter(trial.type =='test')

# Restrict data to only the baseline data

baseline.data = my.data %>% filter(trial == 0)

# Create green object preference variable

baseline.data = baseline.data %>% mutate(green.object.preference = (case_when(
  rewarding.object.colour == "green" ~ (time.with.trained.object-time.with.untrained.object), 
  rewarding.object.colour == "blue" ~ (time.with.untrained.object-time.with.trained.object) 
)))


# Change trial to factor 
test.data$trial = as.factor(test.data$trial)
baseline.data$trial = as.factor(baseline.data$trial)
```

## Models

We analysed the data from our using linear mixed effect and generalized linear mixed effect models with the `lmer()` and `glmer()` functions from `lme4` package. P-values and effective degrees of freedom were obtained using the `lmerTest` package. Model residuals were checked they met distributional assumptions with the `DHARMa` package, you can click the 'See Model Residuals' button below the model formulas to see the residual diagnostic plots produced by `DHARMa` for that particular model. 

### Model 1 -  Preference for the green object at baseline

This first model contains the data for all individual guppies. I looked at the green object preference of all guppies in an intercept only model to see if the green object preference at baseline was significantly different from zero. `green.object.preference` is the time spent near the green object subtracted by the time spent near the blue object

```{r model 1, echo=TRUE}
baseline.data.model = 
  lm(green.object.preference ~ 1,
     data = baseline.data)
```

<button class="btn btn-primary" data-toggle="collapse" data-target="#BlockName"> See Model 1 Residuals </button>  
<div id="BlockName" class="collapse"> 

```{r, echo=FALSE}
simulationOutput <- simulateResiduals(fittedModel = baseline.data.model)
plot(simulationOutput)
```

</div>

</br>

##### Result

```{r tidying-model-1, echo=FALSE, message=FALSE}
# Setting table row names
baseline.table.row.name.vec = c("Intercept")
                       
# Converting data frame to tibble
tidy_baseline.model = broom.mixed::tidy(baseline.data.model)

# Changing tibble header names 
tidy_baseline.model = rename(tidy_baseline.model, "Factor" = term, "Estimate" = estimate, "Std. Error" = std.error, "T statistic" = statistic, "P value" = p.value)

# Changing tibble row names 
tidy_baseline.model[1:1,1] <- baseline.table.row.name.vec
```

```{r,  results=TRUE, echo=FALSE}
knitr::kable(tidy_baseline.model%>% mutate_if(is.numeric, round, digits = 3))
```

During the initial test, there was no significant preference for the green object across all guppies (p = `r tidy_baseline.model$'P value' %>%  round(3)`).


```{r baseline-pref-plot, echo=FALSE, fig.cap="Preference for the green object relative to the blue object across all guppies at baseline. Negative values represent more time spent with the blue object, positive values indicate more time spent with the green object. Data are means +/- 95% CI", fig.id="baseline-pref-plot",  warning=FALSE, message=FALSE}
###### Baseline green object preference plot ######
baseline.data.x.axis.label = 'Initial Test'
ggplot(baseline.data, 
            aes(x = trial, 
                y = green.object.preference)) + theme_classic() + ylab('Green object preference (sec)') + xlab("") + theme(legend.position = "none", axis.text=element_text(size=14), axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5)) + geom_hline(yintercept = 0, linetype = 'dashed', alpha = 0.5) + geom_jitter(width=0.04, alpha = 0.3) + stat_summary(
    geom = 'point',
    fun = 'mean',
    size = 4.5,
    shape = 15) +
  stat_summary(geom = 'errorbar', 
               fun.data = 'mean_ci', position = position_dodge(width=0), width = 0.1)  +
  scale_x_discrete(labels = baseline.data.x.axis.label)

```

***

### Model 2 -  Preference for the rewarding object during training

To see whether fish were responsive during training our second model asks whether the preference for the rewarding object changes throughout training between the treatments. 

##### Variables

- `rewarding.object.preference` is the time (seconds) spent near the rewarding object subtracted by the time spent near the unrewarding object 
- `rewarding.object.colour` is the identity of the rewarding object (blue or green)
- `trial` is the number of the training trial. In this model it is supplied as an integer
- `id` is the identity of the individual fish 

```{r model 2, echo=TRUE}
training.data.model = 
  lmer(rewarding.object.preference ~ rewarding.object.colour * trial + (1 | id), 
       data = training.data)
```

<button class="btn btn-primary" data-toggle="collapse" data-target="#BlockName2"> See Model 2 Residuals </button>  
<div id="BlockName2" class="collapse">  

```{r, echo=FALSE}
simulationOutput <- simulateResiduals(fittedModel = training.data.model, n = 1000)
plot(simulationOutput)
```

There is a slight deviation in the upper quantile but no indication in the residual plot of a gross model misfit.

</div>

```{r tidying-model-2, echo=FALSE, message=FALSE}
# Setting table row names
training.model.table.row.name.vec = c("Intercept", "Reward object colour", "Trial", "Rewarding object colour X Trial")
                       
# Converting data frame to tibble
tidy_training.data.model = broom.mixed::tidy(training.data.model)

# Formatting p value
tidy_training.data.model$p.value = ifelse(tidy_training.data.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_training.data.model$p.value %>% round(3))) ## if condition is false

# Getting model confidence intervals
training.data.model.confint = tibble::as_tibble((training.data.model %>% confint()), rownames = "factor")

# Changing tibble header names 
tidy_training.data.model = rename(tidy_training.data.model, "Factor" = term, "Estimate" = estimate, "Std. Error" = std.error, "T statistic" = statistic, "P value" = p.value)

# Changing tibble row names 
tidy_training.data.model[1:4,3] <- training.model.table.row.name.vec
```

</br>

##### Results

```{r,  results=TRUE, echo=FALSE}
knitr::kable(tidy_training.data.model[1:4,] %>% dplyr::select(-group, -effect)%>% mutate_if(is.numeric, round, digits = 3))
```

Throughout training, over the 20 trials, guppies increased their relative preference for the rewarded object by `r tidy_training.data.model$Estimate[3] %>% round(3)` seconds each trial (Figure \@ref(fig:novel-pref-plot), p = `r tidy_training.data.model$'P value'[3]`). There was also a significant effect of rewarding object colour (p = `r tidy_training.data.model$'P value'[2]`). During training green-rewarded guppies expressed a stronger preference for their rewarded object (the green object) than blue-rewarded guppies did for the blue object However, there was no interaction effect between rewarding object colour and trial (p = `r tidy_training.data.model$'P value'[4]`) suggesting there was no difference in the rate of learning between the treatments

```{r novel-pref-plot, echo=FALSE, fig.cap="Preference for the green object in both treatments. Negative values represent more time spent with the blue object, positive values indicate more time spent with the green object. Faded lines connect individuals across trials and solid lines represents a linear fit with 95% CI (grey shading).", fig.id="novel-pref-plot",  warning=FALSE, message=FALSE}
###### Time with rewarding object plot during training ######
ggplot(training.data, 
            aes(x = trial, 
                y = green.object.preference, 
                color = rewarding.object.colour,
                linetype = rewarding.object.colour)) + 
  theme_cowplot() + 
  ylab('Green object preference (sec)') + 
  xlab("Trial") + 
  labs(col = "Rewarding object colour") +
  theme(legend.position = "none", 
        axis.text=element_text(size=14), 
        axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5)
        ) + 
  scale_color_manual(values=c("#2980b9", "#27ae60")) + 
  scale_linetype_manual(values=c("longdash", "solid")) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line(aes(group = id), alpha = 0.25) + 
  geom_smooth(method = lm)  

```

***

 

### Model 3 -  Preference for the rewarded object during testing depending on treatment {#model-3}

#### Main effects

For the main effects of training and rewarding object colour on rewarding object preference I initially fit a linear mixed effects model with fixed effects of trial and rewarding object colour and a random effect of individual id. 

Due to heterogeneity in the variance among groups however, I switched to a generalized linear mixed effects model with a Gaussian distribution which also modeled the variances to account for variance heterogeneity using the package [`glmmTMB`](https://cran.r-project.org/web/packages/glmmTMB/index.html). My third model asks whether the preference for the rewarding object changed between baseline and final test and looks for an interaction with rewarded object colour.

##### Variables

- `rewarding.object.preference` is the time (seconds) spent near the rewarding object subtracted by the time spent near the unrewarding object 
- `rewarding.object.colour` is the identity of the rewarding object (blue or green)
- `trial` is the number of the training trial. In this model it is supplied as a factor where 0 is the baseline trial and 21 is the final trial
- `id` is the identity of the individual fish 

```{r, include=FALSE}
test.data.model = 
  lmer(rewarding.object.preference ~ trial * rewarding.object.colour + (1 | id),
       data = test.data)
```


```{r model 3, echo=TRUE}
test.data.model.glm = 
  glmmTMB(rewarding.object.preference ~  trial * rewarding.object.colour + (1|id) + 
    diag(0 + rewarding.object.colour:trial |id), 
  data = test.data, family = gaussian)
```

<button class="btn btn-primary" data-toggle="collapse" data-target="#BlockName3"> See Model 3 Residuals </button>  
<div id="BlockName3" class="collapse">  

```{r, include=TRUE,echo=FALSE}
simulationOutput <- simulateResiduals(fittedModel = test.data.model.glm, n = 1000)
plot(simulationOutput)
```

</div>



```{r tidying-model-3, echo=FALSE, message=FALSE}
# Setting table row names
test.model.table.row.name.vec = c("Intercept", "Test type", "Treatment", "Treatment X Test type")
                       
# Converting data frame to tibble
tidy_test.data.model = broom.mixed::tidy(test.data.model)

# Formatting p value
tidy_test.data.model$p.value = ifelse(tidy_test.data.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_test.data.model$p.value %>% round(3))) ## if condition is false

# Getting model confidence intervals
# test.data.model.confint = tibble::as_tibble((test.data.model %>% confint()), rownames = "factor")

# Changing tibble header names 
tidy_test.data.model = rename(tidy_test.data.model, "Factor" = term, "Estimate" = estimate, "Std. Error" = std.error, "T statistic" = statistic, "P value" = p.value)

# Changing tibble row names 
tidy_test.data.model[1:4,3] <- test.model.table.row.name.vec
```

</br>

##### Results

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_test.data.model[1:4,] %>% dplyr::select(-group, -effect) %>% mutate_if(is.numeric, round, digits = 3))
```

I found a significant interaction effect between test type and rewarding object colour (p = `r tidy_test.data.model$'P value'[4]`). Guppies that had the green object rewarded had an increase in rewarded object preference at final test that was `r tidy_test.data.model$Estimate[4] %>% round(1)` seconds stronger than the increase in the rewarded object preference of guppies trained to blue (Figure \@ref(fig:test-data-pref-plot)). 

```{r, include=FALSE}
# We see that there is a significant interaction effect. To see whether both blue-trained and green-trained guppies significantly shift their rewarded object preference

# in response to training I will use the package emmeans to conduct pairwise comparisons of baseline and re-test data across treatments

# Is the difference in rewarding object preference between trials (baseline and re-test) significant in both object treatments (blue-trained and green-trained)?

test.data.model.pairwise.comparisons = emmeans(test.data.model.glm, specs = ~ trial:rewarding.object.colour)

test.data.model.pairwise.comparisons

blue0 = c(1,0,0,0)
blue21 = c(0,1,0,0)
green0 = c(0,0,1,0)
green21 = c(0,0,0,1)



custom.contrasts = contrast(test.data.model.pairwise.comparisons, 
                            method = list("21 blue - 0 blue" = blue21- blue0,
                                          "21 green - 0 green " = green21 - green0,
                                          "21 green - 21 blue" = green21 - blue21,
                                          "0 green - 0 blue" = green0- blue0), adjust = "mvt") %>% summary(infer = TRUE)

# Pull out the summary statistics of the contrasts and turn them into a table
pairwise.comparison.means.table = as.data.frame(test.data.model.pairwise.comparisons)

pairwise.comparison.contrasts.table = as.data.frame(custom.contrasts)

# Rounding contrast table values

formatted_p.pairwise.comparison.contrasts.table = ifelse(pairwise.comparison.contrasts.table$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste("=", pairwise.comparison.contrasts.table$p.value %>% round(3))) ## if condition is false

pairwise.comparison.contrasts.table$estimate = pairwise.comparison.contrasts.table$estimate %>% round(3)
pairwise.comparison.contrasts.table$lower.CL = pairwise.comparison.contrasts.table$lower.CL %>% round(3)
pairwise.comparison.contrasts.table$upper.CL = pairwise.comparison.contrasts.table$upper.CL %>% round(3)
pairwise.comparison.contrasts.table$df = pairwise.comparison.contrasts.table$df %>% round(3)
```


```{r test-data-pref-plot, echo=FALSE, fig.cap="The initial and final rewarding object preference. Dashed line represents the no preference value. Data are means +/- 95% CI. Bold line connects means across trials.", fig.id="test-data-pref-plot", warning=FALSE, message=FALSE}
###### Time with rewarding object plot during training ######
testing.data.x.axis.labels = c("Baseline", "Re-test")
object.labels = c("Blue-trained", "Green-trained")
names(object.labels) <- c("blue", "green")

ggplot(test.data, 
            aes(x = trial, 
                y = rewarding.object.preference, 
                color = rewarding.object.colour,
                shape = rewarding.object.colour)) + 
  theme_cowplot() + 
  geom_jitter(width=0, alpha = 0.3) + 
  stat_summary(geom = 'point', fun = 'mean', size = 4.5) +
  stat_summary(geom = 'errorbar', fun.data = 'mean_ci', position = position_dodge(width=0), width = 0.1) + 
  ylab('Rewarding object preference (sec)') + 
  xlab("Trial") + 
  labs(col = "Rewarding object colour") +
  theme(legend.position = "none", 
        axis.text=element_text(size=14), 
        axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5)
        ) + 
  scale_color_manual(values=c("#2980b9", "#27ae60")) + 
  scale_shape_manual(values=c(15,16)) +
  geom_hline(yintercept = 0, linetype = 'dashed', alpha = 0.6) +
  geom_line(aes(group = id), alpha = 0.2) +
  scale_x_discrete(labels = testing.data.x.axis.labels) + 
  facet_grid(~rewarding.object.colour, labeller = labeller(rewarding.object.colour = object.labels)) +
  stat_summary(fun=mean, geom="line", aes(group = rewarding.object.colour))
```



</br>

#### Post-hoc Comparisons

To determine whether the means of the final rewarding object preference for the two treatments were different I conducted post-hoc comparisons with the package [`emmeans`](https://cran.r-project.org/package=emmeans). I compared the following means:

- Final test blue-trained and initial test blue-trained
- Final test green-trained and initial test green-trained
- Final test green-trained and final test blue-trained
- Initial test green-trained and initial test blue-trained

```{r, echo=TRUE, eval=FALSE}
test.data.model.pairwise.comparisons = 
  emmeans(test.data.model.glm, specs = ~ trial:rewarding.object.colour)

custom.contrasts = contrast(test.data.model.pairwise.comparisons, 
                            method = list("21 blue - 0 blue" = blue21- blue0,
                                          "21 green - 0 green " = green21 - green0,
                                          "21 green - 21 blue" = green21 - blue21,
                                          "0 green - 0 blue" = green0- blue0), 
                            adjust = "mvt") %>% summary(infer = TRUE)
```

</br>

##### Results

```{r contrasts-table, echo=FALSE, fig.id="contrasts-table", warning=FALSE}
pairwise.comparison.contrasts.table.show = pairwise.comparison.contrasts.table

pairwise.comparison.contrasts.table.show$p.value = 
  case_when(pairwise.comparison.contrasts.table.show$p.value < .001 ~ paste('< .001'),
            (pairwise.comparison.contrasts.table.show$p.value < .05 & pairwise.comparison.contrasts.table.show$p.value >= .001) ~ paste(as.character(pairwise.comparison.contrasts.table.show$p.value %>% round(3))),
            pairwise.comparison.contrasts.table.show$p.value >= .05 ~ paste(pairwise.comparison.contrasts.table.show$p.value %>% round(3)))

knitr::kable(pairwise.comparison.contrasts.table.show %>% dplyr::select(contrast, estimate,lower.CL,upper.CL, df,p.value), caption = "Table of post-hoc tests with a multivariate-t adjustment for multiple comparisons of a selected set of means. The numbers represent the initial test trial (0) and the final test trial (21). The colour corressponds to the identity of the rewarding object (blue for blue-trained guppies, green for green-trained guppies). Values are all rounded to 3 decimal places. CL = confidence limit")

```

Post-hoc comparisons investigating the differences between treatments based on whether guppies are untrained or trained reveals that initially, when untrained, there was no difference in the strength of preference for the rewarding object between the treatments (blue-trained guppies had a blue object preference of `r pairwise.comparison.means.table$emmean[1] %>% round(1)` seconds and green-trained guppies had a green object preference of `r pairwise.comparison.means.table$emmean[3] %>% round(1)` seconds, p `r formatted_p.pairwise.comparison.contrasts.table[4]`). 

Comparing the shift in rewarding object preference between initial and final preference tests in blue-trained and green-trained guppies reveals that the shift in rewarding object preference is significant for green-trained guppies but not for blue-trained guppies. Green trained guppies increased their preference for the green object by `r abs(pairwise.comparison.contrasts.table$estimate[2] %>% round(1))` seconds (going from a green object preference of `r pairwise.comparison.means.table$emmean[3] %>% round(1)` seconds initially to `r pairwise.comparison.means.table$emmean[4] %>% round(1)` seconds at final test, p `r formatted_p.pairwise.comparison.contrasts.table[2]`) whereas blue-trained guppies non-significantly increased their preference for the blue object by `r abs(pairwise.comparison.contrasts.table$estimate[1] %>% round(1))` seconds (going from a blue object preference `r pairwise.comparison.means.table$emmean[1] %>% round(1)` seconds initially to `r (pairwise.comparison.means.table$emmean[2]) %>% round(1)` seconds at final test, p `r formatted_p.pairwise.comparison.contrasts.table[1]`). For a full description of post-hoc comparisons see table \@ref(tab:contrasts-table).

***


```{r, include = FALSE}
#### Get feeding data #####
# Group by ID and count the number of sessions in which an individual ate 
feeding = my.data %>% group_by(id) %>%  count(feeding.count = ate == 'yes')
feeding
# Remove NAs from this 
feeding = na.omit(feeding)
feeding
# Count only the yeses
feeding = feeding %>% filter(feeding.count == 'TRUE')
# Remove the column session.ate to keep only the counts
feeding = feeding %>% dplyr::select(-feeding.count)
feeding

# Add the feeding values to the main data frame and replace NAs with 0 
my.feeding.data = left_join(baseline.data, feeding, by ="id")
my.feeding.data = my.feeding.data %>% replace_na(list(n = 0))
my.feeding.data
my.feeding.data = rename(my.feeding.data, feeding.count = n)
my.feeding.data =  my.feeding.data %>% dplyr::select(id,feeding.count,rewarding.object.colour)
my.feeding.data
```

### Model 4 - Is there a difference in feeding attempts between treatments? {#model-4}

A discrepancy in reinforcement between treatments may influence performance on a final preference test. To see whether there was a difference in feeding between treatments I counted the number of trials in which an individual fish ate throughout all of training and compared the feeding counts between treatments. To do this I fit a generalized linear model with a negative binomial distribution. The response variable 'feeding count' is a sum of the number of trials in which a guppy ate.

##### Variables

- `feeding.count` is the number of trials in which an individual fish ate
- `rewarding.object.colour` is the identity of the rewarding object (blue or green)

##### Model

```{r model 4, echo=TRUE}
feeding.data.model = 
  glm.nb(feeding.count ~ rewarding.object.colour, 
      data = my.feeding.data)
```

<button class="btn btn-primary" data-toggle="collapse" data-target="#BlockName4"> See Model 4 Residuals </button>  
<div id="BlockName4" class="collapse">  

```{r, echo=FALSE}
simulationOutput <- simulateResiduals(fittedModel = feeding.data.model)
plot(simulationOutput)
```

</div>

```{r tidying-model-4, echo=FALSE, message=FALSE}
# Setting table row names
feeding.model.table.row.name.vec = c("Intercept", "Rewarding object colour")
                       
# Converting data frame to tibble
tidy_feeding.data.model = broom.mixed::tidy(feeding.data.model)

# Getting model confidence intervals
feeding.data.model.confint = tibble::as_tibble((feeding.data.model %>% confint()), rownames = "factor")

# Changing tibble header names 
tidy_feeding.data.model = rename(tidy_feeding.data.model, "Factor" = term, "Estimate" = estimate, "Std. Error" = std.error, "T statistic" = statistic, "P value" = p.value)

# Changing tibble row names 
tidy_feeding.data.model[1:2,1] <- feeding.model.table.row.name.vec
```

</br>

##### Results

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_feeding.data.model[1:2,]%>% mutate_if(is.numeric, round, digits = 3))
```

I found no significant difference in the amount of feeding done by individuals trained to green versus individuals trained to blue (Figure \@ref(fig:feeding-count-plot), p = `r tidy_feeding.data.model$'P value'[2]`) which suggests that the observed group-level differences in final test performance between blue-trained guppies versus green-trained guppies  cannot be explained by differences in performance during training.  

```{r feeding-count-plot, echo=FALSE, fig.cap="Average number of trials in which a fish fed during training. Data are means +/- 95% confidence intervals with probability density functions of the data to the right of the raw data.", fig.id="training-data-ate-plot", warning=FALSE}
source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")
ggplot(my.feeding.data,
             aes(x=rewarding.object.colour,
                 y=feeding.count, 
                 fill = rewarding.object.colour, 
                 colour = rewarding.object.colour)) +
  geom_point(position = position_jitter(width = 0.05), alpha = 0.8) +
  geom_flat_violin(aes(fill = rewarding.object.colour),position = position_nudge(x = .25, y = 0),adjust = 0.7, alpha = 0.4, trim = FALSE, color=NA) + 
  stat_summary(geom = 'point', fun = 'mean', size = 4.5, shape = 15) +
  stat_summary(geom = 'errorbar', fun.data = 'mean_ci', position = position_dodge(width=0), width = 0.1) + ylim(-3,23) +
  ylab('Rewarding object preference')+xlab('Trial') + theme_cowplot()+ guides(fill = FALSE, colour = FALSE) + ylab('Number of trials fed') + xlab("Rewarding object colour") + labs(col = "Rewarding object colour") +
  theme(legend.position = "top", axis.text=element_text(size=14), axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5)) +
  scale_color_manual(values=c("#2980b9", "#27ae60"))+
  scale_fill_manual(values=c("#2980b9", "#27ae60"))
```


## ESM Models

### ESM Model 1 - Preference for the rewarded object during training based on feeding

It might be the case that some fish behaved in a way that was not conducive to learning the association during training. My fourth model asks whether the time spent near the rewarding object during a training session is influenced by whether a fish ate or not. Here trial is a variable containing the training trials (1-20). It is supplied as a random effect along with individual ID in the model. 

##### Variables

- `rewarding.object.preference` is the time (seconds) spent near the rewarding object subtracted by the time spent near the unrewarding object 
- `ate` is a binary factor (Yes or No) and corresponds to whether the fish ate in a given trial
- `trial` is the number of the training trial. In this model it is supplied as an integer
- `id` is the identity of the individual fish 

##### Model

```{r esm-model-1, echo=TRUE}
training.data.model.rewarding.object = 
  lmer(rewarding.object.preference ~ ate + (1 | id) + (1 | trial),
       data = training.data)
```

<button class="btn btn-primary" data-toggle="collapse" data-target="#BlockName5"> See ESM Model 1 Residuals </button>  
<div id="BlockName5" class="collapse">  

```{r, echo=FALSE}
simulationOutput <- simulateResiduals(fittedModel = training.data.model.rewarding.object, n = 1000)
plot(simulationOutput)
```

There is a significant deviation from uniformity as indicated by the significant Kolmogorov-Smirnov test. However, this model has a particularly large sample size (n = 456) so even slight deviations will be significant. Looking at the effect size of the deviation (D = `r testUniformity(simulationOutput)[1]`) shows that it is minor (D < 0.1) and visual inspection does not suggest large deviations in the residuals so our model is still appropriate.

</div>

</br>

```{r, echo=FALSE, results=FALSE}
# Summary ofesm model 1
tidy_fit.rewarding.object = broom.mixed::tidy(training.data.model.rewarding.object)
tidy_fit.rewarding.object$p.value = ifelse(tidy_fit.rewarding.object$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.rewarding.object$p.value %>% round(3))) ## if condition is false
tidy_fit.rewarding.object[2:2,] %>% dplyr::select(-group, -effect)
```

##### Results

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.rewarding.object[2:2,] %>% dplyr::select(-group, -effect)%>% mutate_if(is.numeric, round, digits = 3))
```


```{r, include=FALSE}
# Summary of model 4

summary(training.data.model.rewarding.object)

# This is needed to get the model output in a format that can be referenced later

tidy_fit.rewarding.object = broom.mixed::tidy(training.data.model.rewarding.object)

# This formats the p-value depending on whether it is less than 0.001. If that is true
# it will just report p < .001 otherwise it will give the exact value rounded to 3 decimal points

formatted_p.rewarding.object = ifelse(tidy_fit.rewarding.object$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste("=", tidy_fit.rewarding.object$p.value %>% round(3))) ## if condition is false
```

Throughout all of training, fish that ate during a session spent on average `r tidy_fit.rewarding.object$estimate[2] %>% round(1)` more seconds near the rewarded object compared to fish that did not eat (Figure, \@ref(fig:training-data-ate-plot), p `r formatted_p.rewarding.object[2]`). Fish that spent more trials eating may therefore have received more reinforcement for the object-food association. This result is what led me to investigate whether there was a difference in food reinforcement between the two treatments in [Model 4](#model-4). 
</br>

```{r training-data-ate-plot, echo=FALSE, fig.cap="Preference for the rewarding object during training based on whether an individual ate during a trial or not. Dashed line represents the no preference value. In panel A, Data are means +/- 95% CI. In panel B, the data consist of all the feeding choices of all individuals across all training trials. Data are means +/- 95% CI with probability density functions to the right of the raw data.", fig.id="training-data-ate-plot", warning=FALSE}
###### Time with rewarding object plot during training [gaussian] ######
source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")

p1 = ggplot(training.data, 
            aes(x = trial, 
                y = rewarding.object.preference, 
                color = ate)) + theme_cowplot() + geom_jitter(width=0.05, alpha = 0.2) + stat_summary(
    geom = 'point',
    fun = 'mean',
    size = 4.5,
    shape = 15) +
  stat_summary(geom = 'errorbar', 
               fun.data = 'mean_ci', position = position_dodge(width=0), width = 0.1) + ylab('Rewarding object preference (sec)') + xlab("Trial") + labs(col = "Did this individual eat this trial?") +
  theme(legend.position = "top", axis.text=element_text(size=14), axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5), panel.border = element_rect(colour = "black", fill=NA, size=1), axis.line.x = element_blank(), axis.line.y = element_blank()) + scale_color_manual(values=c('#696667','#0f85a0')) + 
  geom_hline(yintercept = 0, linetype = 'dashed') + ylim(-310,310)

p2 = ggplot(training.data, 
            aes(x = trial.type, 
                y = rewarding.object.preference, 
                color = ate)) + theme_cowplot() + geom_jitter(width=0.05, alpha = 0.1) +
  geom_flat_violin(aes(fill = ate),position = position_nudge(x = .25, y = 0),adjust = 1, alpha = 0.6, trim = TRUE, color=NA) + stat_summary(
    geom = 'point',
    fun = 'mean',
    size = 3,
    shape = 15) +
  stat_summary(geom = 'errorbar', 
               fun.data = 'mean_ci', position = position_dodge(width=0), width = 0.15) + xlab("") + ylab("Rewarding object preference (sec)")+
  theme(legend.position = "none", axis.text=element_text(size=14), axis.title=element_text(size=12.5,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5), axis.ticks.x = element_blank(), axis.line.y = element_blank(), axis.line.x = element_blank(), axis.text.y = element_blank(), axis.ticks.y =  element_blank(), axis.title.y = element_blank(),panel.border = element_rect(colour = "black", fill=NA, size=1)) + scale_color_manual(values=c('#696667','#0f85a0')) + scale_fill_manual(values=c('#696667','#0f85a0')) + 
  geom_hline(yintercept = 0, linetype = 'dashed') + ylim(-310,310) +
  scale_x_discrete(labels = "")

ggarrange(p1,p2, widths = c(1.5,1),
          labels = "AUTO",
          label.x = c(0.15,0),
          hjust = -2,
          vjust = 3,
          common.legend = TRUE)
```



### ESM Model 2 - Controlling for feeding count

##### Variables

- `rewarding.object.preference` is the time (seconds) spent near the rewarding object subtracted by the time spent near the unrewarding object 
- `rewarding.object.colour` is the identity of the rewarding object (blue or green)
- `trial` is the number of the training trial. In this model it is supplied as an integer
- `id` is the identity of the individual fish 
- `feeding.count` is the number of trials in which an individual fish ate


#### ESM Model 2a - Removing individual that did not feed

```{r, include=FALSE}
test.feeding.data = left_join(test.data, feeding, by ="id")
test.feeding.data = test.feeding.data %>% replace_na(list(n = 0))
test.feeding.data = rename(test.feeding.data, feeding.count = n)
retest.feeding.data = test.feeding.data %>% filter(trial == "21")
retest.feeding.data = retest.feeding.data %>% mutate(time.with.both.objects = time.with.trained.object+time.with.untrained.object)
```

There is a fish that did not eat during any trials, however removing this individual does not change the conclusions 

##### Model

```{r, echo=TRUE}
test.feeding.data.low.feeders.removed = test.feeding.data %>% filter(feeding.count > 0)

test.feeding.data.low.feeders.removed.model = 
  glmmTMB(rewarding.object.preference ~  trial * rewarding.object.colour + (1|id) + 
    diag(0 + rewarding.object.colour:trial |id),
    data = test.feeding.data.low.feeders.removed, family = gaussian)
```

<button class="btn btn-primary" data-toggle="collapse" data-target="#BlockName6"> See ESM Model 2a Residuals </button>  
<div id="BlockName6" class="collapse">  

```{r, echo=FALSE}
simulationOutput <- simulateResiduals(fittedModel = test.feeding.data.low.feeders.removed.model)
plot(simulationOutput)
```

</div>

</br>

```{r, echo=FALSE, results=FALSE}
tidy_fit.test.feeding.data.low.feeders.removed = broom.mixed::tidy(test.feeding.data.low.feeders.removed.model)
tidy_fit.test.feeding.data.low.feeders.removed$p.value = ifelse(tidy_fit.test.feeding.data.low.feeders.removed$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.test.feeding.data.low.feeders.removed$p.value %>% round(3))) ## if condition is false
tidy_fit.test.feeding.data.low.feeders.removed
```

##### Results

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.test.feeding.data.low.feeders.removed[2:4,] %>% dplyr::select(-group, -effect, -component)%>% mutate_if(is.numeric, round, digits = 3))
```



#### ESM Model 2b - Including feeding count as a covariate

Moreover, as I demonstrate in the next model including the amount of trials fed as a covariate in the model does not change the conclusions.

```{r, echo = TRUE}
test.data.feeding.controlled.model = 
  glmmTMB(rewarding.object.preference ~  trial * rewarding.object.colour + feeding.count + (1|id) + 
    diag(0 + rewarding.object.colour*trial |id), 
  data = test.feeding.data, family = gaussian)
```

<button class="btn btn-primary" data-toggle="collapse" data-target="#BlockName7"> See ESM Model 2b Residuals </button>  
<div id="BlockName7" class="collapse">  

```{r, echo=FALSE}
simulationOutput <- simulateResiduals(fittedModel = test.data.feeding.controlled.model)
plot(simulationOutput)
```

</div>

</br>
```{r, echo=FALSE, results=FALSE}
# Summary of model 6
tidy_fit.test.data.feeding.controlled.model = broom.mixed::tidy(test.data.feeding.controlled.model)
tidy_fit.test.data.feeding.controlled.model$p.value = ifelse(tidy_fit.test.data.feeding.controlled.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.test.data.feeding.controlled.model$p.value %>% round(3))) ## if condition is false
tidy_fit.test.data.feeding.controlled.model[2:5,]
```

##### Results

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.test.data.feeding.controlled.model[2:5,]%>% dplyr::select(-group, -effect, -component)%>% mutate_if(is.numeric, round, digits = 3))
```


The main results do not change if I control for feeding count. The above table is the output feeding controlled model. Below we have the output table for the non-feeding-count controlled model from [Model 3](#model-3).

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_test.data.model[2:4,] %>% dplyr::select(-group, -effect)%>% mutate_if(is.numeric, round, digits = 3))
```

In both models the p-values are similar. While the effect of feeding count is not significant (p = `r tidy_fit.test.data.feeding.controlled.model$p.value[4]`) the effect of feeding count trends in the expected direction in our feeding count controlled model. As feeding count increases the preference for the rewarding object colour also increases.

***

</br>

## Tools used and References

A complete list of the tools used is produced below:


```{r, echo=FALSE}
knitr::kable(as.data.frame(report(sessionInfo())))
```

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>
