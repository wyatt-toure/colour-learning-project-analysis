
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r data-prep, include=FALSE}
library(PNWColors)
library(lme4)
library(tidyr)
library(lmerTest)
library(psych)
library(ggplot2)
library(ggpubr)
library(DHARMa)
library(rptR)
library(dplyr)
library(gganimate)
library(Hmisc)
library(effects)
library(RColorBrewer)
library(broom)
library(broom.mixed)
library(knitr)
library(emmeans)
library(pbkrtest)
library(formattable)
library(report)

#### Reading in Data 
my.data = read.csv('experiment-2-master-sheet-clean.csv')

# Crerating new variables 
my.data = my.data %>% group_by(id) %>% mutate(rewarding.object.preference = (time.with.trained.object-time.with.untrained.object))

my.data = my.data %>% mutate(green.object.preference = (case_when(
  rewarding.object.colour == "green" ~ (time.with.trained.object-time.with.untrained.object), 
  rewarding.object.colour == "blue" ~ (time.with.untrained.object-time.with.trained.object) 
)))

training.data = my.data %>% filter(trial.type =='training')

# Restrict data to only the baseline and re-test data

test.data = my.data %>% filter(trial.type =='test')

# Restrict data to only the baseline data

baseline.data = my.data %>% filter(trial == 0)

# Create green object preference variable

baseline.data = baseline.data %>% mutate(green.object.preference = (case_when(
  rewarding.object.colour == "green" ~ (time.with.trained.object-time.with.untrained.object), 
  rewarding.object.colour == "blue" ~ (time.with.untrained.object-time.with.trained.object) 
)))


# Change trial to factor 
test.data$trial = as.factor(test.data$trial)
baseline.data$trial = as.factor(baseline.data$trial)
```



# Model 1 -  Preference for the green object at baseline

This first model contains the data for all individual guppies. I looked at the green object preference of all guppies in an intercept only model to see if the green object preference at baseline was significantly different from zero.
```{r model 1, echo=TRUE}
baseline.data.model = 
  lm(green.object.preference ~ 1,
     data = baseline.data)
```

```{r, include=FALSE}
# Summary of model 1

summary(baseline.data.model)

# This is needed to get the model output in a format that can be referenced later

baseline.data.model.tidy_fit = broom.mixed::tidy(baseline.data.model)

# This formats the p-value depending on whether it is less than 0.001. If that is true
# it will just report p < .001 otherwise it will give the exact value rounded to 3 decimal points

baseline.data.model.formatted_p = ifelse(baseline.data.model.tidy_fit$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste("=", baseline.data.model.tidy_fit$p.value %>% round(3))) ## if condition is false
```

At baseline, there was no significant preference for the green object preference across all guppies (p `r baseline.data.model.formatted_p[1]`).

```{r, echo=FALSE, results=FALSE}
tidy_fit0 = broom.mixed::tidy(baseline.data.model)
tidy_fit0$p.value = ifelse(tidy_fit0$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit0$p.value %>% round(3))) ## if condition is false
tidy_fit0
```

```{r,  results=TRUE, echo=FALSE}
knitr::kable(tidy_fit0)
```


# Model 2 -  Preference for the rewarding object during training

To see whether fish were responsive during training our second model asks whether the preference for the rewarding object changes throughout training between the treatments.

```{r model 2, echo=TRUE}
training.data.model = 
  lmer(rewarding.object.preference ~ rewarding.object.colour * trial + (1 | id), 
       data = training.data)
```

```{r, echo=FALSE, results=FALSE}
# Summary of model 3
tidy_fit = broom.mixed::tidy(training.data.model)
tidy_fit$p.value = ifelse(tidy_fit$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit$p.value %>% round(3))) ## if condition is false
tidy_fit[2:4,] %>% select(-group, -effect)

```

```{r,  results=TRUE, echo=FALSE}
knitr::kable(tidy_fit[2:4,] %>% select(-group, -effect))
```


```{r, include=FALSE}
# Summary of model 2

summary(training.data.model)

# This is needed to get the model output in a format that can be referenced later

tidy_fit = broom.mixed::tidy(training.data.model)

# This formats the p-value depending on whether it is less than 0.001. If that is true
# it will just report p < .001 otherwise it will give the exact value rounded to 3 decimal points

formatted_p = ifelse(tidy_fit$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste("=", tidy_fit$p.value %>% round(3))) ## if condition is false
```

Throughout training, over the 20 trials, guppies increased their relative preference for the rewarded object by `r tidy_fit$estimate[3] %>% round(3)` seconds each trial (Figure \@ref(fig:novel-pref-plot), p `r formatted_p[3]`).

```{r novel-pref-plot, echo=FALSE, fig.cap="Preference for the green object in both treatments. Negative values represent more time spent with the blue object, positive values indicate more time spent with the green object. Faded lines connect individuals across trials and solid lines represents a linear fit with 95% CI (grey shading).", fig.id="novel-pref-plot",  warning=FALSE, message=FALSE}
###### Time with rewarding object plot during training [gaussian] ######
ggplot(training.data, 
            aes(x = trial, 
                y = green.object.preference, 
                color = rewarding.object.colour)) + theme_classic() + ylab('Green object preference (sec)') + xlab("Trial") + 
  labs(col = "Rewarding object colour") +
  theme(legend.position = "top", axis.text=element_text(size=14), axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5)) + scale_color_manual(values=c("#2980b9", "#27ae60")) + 
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line(aes(group = id), alpha = 0.3, arrow = arrow(angle = 30, length = unit(0, "inches"), ends = "first", type = "closed"), lty = 1) + geom_smooth(method = lm)  

```


# Model 3 -  Preference for the rewarded object during testing depending on treatment

For the main effects of **training** and **rewarding object colour** on object preference I fit a **linear mixed effects model** with **fixed effects of trial** and **rewarding object colour** and a random effect of **individual id**. My third model asks whether the preference for the rewarding object changed between baseline and final test and looks for an interaction with rewarded object colour. In this model trial is a categorical variable composed of the intial preference trial (trial 0) and the final preference trial (trial 21). 


```{r model 3, echo=TRUE}
test.data.model = 
  lmer(rewarding.object.preference ~ rewarding.object.colour * trial + (1 | id),
       data = test.data)
```

```{r, echo=FALSE, results=FALSE}
# Summary of model 3
tidy_fit.test.data.model = broom.mixed::tidy(test.data.model)

tidy_fit.test.data.model$p.value = ifelse(tidy_fit.test.data.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.test.data.model$p.value %>% round(3))) ## if condition is false

tidy_fit.test.data.model[2:4,] %>% select(-group, -effect)
```


```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.test.data.model[2:4,] %>% select(-group, -effect))
```


```{r, include=FALSE}

# This is needed to get the model output in a format that can be referenced later

tidy_fit.test.data.model = broom.mixed::tidy(test.data.model)

# This formats the p-value depending on whether it is less than 0.001. If that is true
# it will just report p < .001 otherwise it will give the exact value rounded to 3 decimal points

formatted_p.test.data.model = ifelse(tidy_fit.test.data.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste("=", tidy_fit.test.data.model$p.value %>% round(3))) ## if condition is false

# We see that there is a significant interaction effect. To see whether both blue-trained and green-trained guppies significantly shift their rewarded object preference
# in response to training I will use the package emmeans to conduct pairwise comparisons of baseline and re-test data across treatments

# Is the differencee in rewarding object preference between trials (baseline and re-test) significant in both object treatments (blue-trained and green-trained)?

test.data.model.pairwise.comparisons = emmeans(test.data.model, specs = pairwise ~ trial:rewarding.object.colour) %>% 
  summary(infer = TRUE)

# Pull out the summary statistics of the contrasts and turn them into a table
pairwise.comparison.means.table = as.data.frame(test.data.model.pairwise.comparisons$emmeans)

pairwise.comparison.contrasts.table = as.data.frame(test.data.model.pairwise.comparisons$contrasts)

# Rounding contrast table values

formatted_p.pairwise.comparison.contrasts.table = ifelse(pairwise.comparison.contrasts.table$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste("=", pairwise.comparison.contrasts.table$p.value %>% round(3))) ## if condition is false

pairwise.comparison.contrasts.table$estimate = pairwise.comparison.contrasts.table$estimate %>% round(3)
pairwise.comparison.contrasts.table$lower.CL = pairwise.comparison.contrasts.table$lower.CL %>% round(3)
pairwise.comparison.contrasts.table$upper.CL = pairwise.comparison.contrasts.table$upper.CL %>% round(3)
pairwise.comparison.contrasts.table$df = pairwise.comparison.contrasts.table$df %>% round(3)
```

I found a significant interaction effect between trial and rewarding object colour (p `r formatted_p.test.data.model[4]`). Guppies that had green rewarded had a rewarded object preference that was `r tidy_fit.test.data.model$estimate[4] %>% round(1)` seconds stronger than the rewarded object preference of guppies trained to blue (Figure \@ref(fig:test-data-pref-plot)). 

<center>
```{r test-data-pref-plot, echo=FALSE, fig.cap="The initial and final rewarding object preference. Dashed line represents the no preference value. Data are means +/- 95% CI. Bold line connects means across trials.", fig.id="test-data-pref-plot", warning=FALSE, message=FALSE}
###### Time with rewarding object plot during training [gaussian] ######
testing.data.x.axis.labels = c("Baseline", "Re-test")
object.labels = c("Blue-trained", "Green-trained")
names(object.labels) <- c("blue", "green")


# dat <- data.frame(Group = c("0", "21", "0", "21"),
#               Sub   = c("green", "green", "blue", "blue"),
#               Value = c(3,5,7,8))  

ggplot(test.data, 
            aes(x = trial, 
                y = rewarding.object.preference, 
                color = rewarding.object.colour)) + theme_classic() + geom_jitter(width=0, alpha = 0.3) + stat_summary(
    geom = 'point',
    fun = 'mean',
    size = 4.5,
    shape = 15) +
  stat_summary(geom = 'errorbar', 
               fun.data = 'mean_ci', position = position_dodge(width=0), width = 0.1) + ylab('Rewarding object preference (sec)') + xlab("Trial") + labs(col = "Rewarding object colour") +
  theme(legend.position = "top", axis.text=element_text(size=14), axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5)) + scale_color_manual(values=c("#2980b9", "#27ae60")) + 
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line(aes(group = id), alpha = 0.3, arrow = arrow(angle = 30, length = unit(0, "inches"), ends = "first", type = "closed"), lty = 1) +
  scale_x_discrete(labels = testing.data.x.axis.labels) + facet_grid(~rewarding.object.colour, labeller = labeller(rewarding.object.colour = object.labels)) +
  stat_summary(fun=mean, geom="line", aes(group = rewarding.object.colour))
```
</center>

Post-hoc pairwise comparisons investigating the differences between treatments based on whether guppies are untrained or trained reveals that initially there was no difference in the strength of preference for the rewarding object between the treatments (blue-trained guppies had a blue object preference of `r pairwise.comparison.means.table$emmean[1] %>% round(1)` seconds and green-trained guppies had a green object preference of `r pairwise.comparison.means.table$emmean[3] %>% round(1)` seconds, p `r formatted_p.pairwise.comparison.contrasts.table[2]`). 

Comparing the shift in rewarding object preference between initial and final preference tests in blue-trained and green-trained guppies reveals that the shift in rewarding object preference is significant for green-trained guppies but not for blue-trained guppies. Green trained guppies increased their preference for the green object by `r abs(pairwise.comparison.contrasts.table$estimate[6] %>% round(1))` seconds (going from a green object preference of `r pairwise.comparison.means.table$emmean[3] %>% round(1)` seconds initially to `r pairwise.comparison.means.table$emmean[4] %>% round(1)` seconds at final test, p `r formatted_p.pairwise.comparison.contrasts.table[6]`) whereas blue-trained guppies non-significantly increased their preference for the blue object by `r abs(pairwise.comparison.contrasts.table$estimate[1] %>% round(1))` seconds (going from a blue object preference `r pairwise.comparison.means.table$emmean[1] %>% round(1)` seconds initially to `r (pairwise.comparison.means.table$emmean[2]) %>% round(1)` seconds at final test, p `r formatted_p.pairwise.comparison.contrasts.table[1]`). For a full description of post-hoc comparisons see table \@ref(tab:contrasts-table).

Overall I find that:

1. <b>Green-trained guppies</b> increased their preference for the green object. 
2. <b>Blue-trained guppies </b> non-significantly increased their preference for the blue object. 
<br />
<br />
<br />

```{r contrasts-table, echo=FALSE, fig.id="contrasts-table", warning=FALSE}
pairwise.comparison.contrasts.table.show = pairwise.comparison.contrasts.table

pairwise.comparison.contrasts.table.show$p.value = 
  case_when(pairwise.comparison.contrasts.table.show$p.value < .001 ~ paste('**< .001**'),
            (pairwise.comparison.contrasts.table.show$p.value < .05 & pairwise.comparison.contrasts.table.show$p.value >= .001) ~ paste(as.character(pairwise.comparison.contrasts.table.show$p.value %>% round(3))),
            pairwise.comparison.contrasts.table.show$p.value >= .05 ~ paste(pairwise.comparison.contrasts.table.show$p.value %>% round(3)))

## Rename contrast levels
# levels(pairwise.comparison.contrasts.table$contrast) <- c(levels(pairwise.comparison.contrasts.table$contrast), "initial  blue trained - final  blue trained")
# levels(pairwise.comparison.contrasts.table$contrast) <- c(levels(pairwise.comparison.contrasts.table$contrast), "initial  blue trained - initial  green trained")
# levels(pairwise.comparison.contrasts.table$contrast) <- c(levels(pairwise.comparison.contrasts.table$contrast), "initial  blue trained - final  green trained")
# levels(pairwise.comparison.contrasts.table$contrast) <- c(levels(pairwise.comparison.contrasts.table$contrast), "final  blue trained - initial  green trained")
# levels(pairwise.comparison.contrasts.table$contrast) <- c(levels(pairwise.comparison.contrasts.table$contrast), "final  blue trained - final  green trained")
# levels(pairwise.comparison.contrasts.table$contrast) <- c(levels(pairwise.comparison.contrasts.table$contrast), "initial  green trained - final  green trained")
# 
# 
# pairwise.comparison.contrasts.table$contrast[pairwise.comparison.contrasts.table$contrast == '0 blue - 21 blue'] <- "initial  blue trained - final  blue trained"
# pairwise.comparison.contrasts.table$contrast[pairwise.comparison.contrasts.table$contrast == '0 blue - 0 green'] <- "initial  blue trained - initial  green trained"
# pairwise.comparison.contrasts.table$contrast[pairwise.comparison.contrasts.table$contrast == '0 blue - 21 green'] <- "initial  blue trained - final  green trained"
# pairwise.comparison.contrasts.table$contrast[pairwise.comparison.contrasts.table$contrast == '21 blue - 0 green'] <- "final  blue trained - initial  green trained"
# pairwise.comparison.contrasts.table$contrast[pairwise.comparison.contrasts.table$contrast == '21 blue - 21 green'] <- "final  blue trained - final  green trained"
# pairwise.comparison.contrasts.table$contrast[pairwise.comparison.contrasts.table$contrast == '0 green - 21 green'] <- "initial  green trained - final  green trained"

knitr::kable(pairwise.comparison.contrasts.table.show %>% select(contrast, estimate, df, lower.CL,upper.CL,p.value),
             caption = "Table of post-hoc tests with Tukey adjustment for multiple comparisons. The numbers represent the initial test trial (0) and the final test trial (21). The colour corressponds to the identity of the rewarding object (blue for blue-trained guppies, green for green-trained guppies). Values are all rounded to 3 decimal places. Significant p-values are bolded.")

```
<br />
<br />

**Testing blue-trained guppies separately**

It does look like blue trained guppies are shifting their preference slightly but the effect might be getting drowned out by the large shift in preference of green-trained guppies so I looked at blue-trained guppies alone in a separate model.

```{r, echo=TRUE}
blue.guppies.test.data = test.data %>% filter(rewarding.object.colour == 'blue')
```

```{r, echo=TRUE}
blue.guppies.test.data.model = 
  lm(rewarding.object.preference ~ trial,
       data = blue.guppies.test.data)
```

```{r,results=FALSE,echo=FALSE}
tidy_fit.blue.test.data.model = broom.mixed::tidy(blue.guppies.test.data.model)
tidy_fit.blue.test.data.model$p.value = ifelse(tidy_fit.blue.test.data.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.blue.test.data.model$p.value %>% round(3))) ## if condition is false
tidy_fit.blue.test.data.model
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.blue.test.data.model)
```


We see that the shift in preference between baseline trial and the final trial is still not significant (p = `r tidy_fit.blue.test.data.model$p.value[2]`) in blue trained guppies though there seems to be a definite trend and the effect is in the expected direction. The random effect of ID was dropped here since it led to a singular fit, there was much more residual variance compared to individual variance, ID random effect did not significantly improve model fit. 

# Model 4 - Preference for the rewarded object during training based on feeding

It might be the case that some fish behaved in a way that was not conducive to learning the association during training. My fourth model asks whether the time spent near the rewarding object during a training session is influenced by whether a fish ate or not. Here trial is a variable containing the training trials (1-20). It is supplied as a random effect along with individual ID in the model. 

```{r model 4, echo=TRUE}
training.data.model.rewarding.object = 
  lmer(rewarding.object.preference ~ ate + (1 | id) + (1 | trial),
       data = training.data)
```

```{r, echo=FALSE, results=FALSE}
# Summary of model 4
tidy_fit.rewarding.object = broom.mixed::tidy(training.data.model.rewarding.object)
tidy_fit.rewarding.object$p.value = ifelse(tidy_fit.rewarding.object$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.rewarding.object$p.value %>% round(3))) ## if condition is false
tidy_fit.rewarding.object[2:2,] %>% select(-group, -effect)
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.rewarding.object[2:2,] %>% select(-group, -effect))
```


```{r, include=FALSE}
# Summary of model 4

summary(training.data.model.rewarding.object)

# This is needed to get the model output in a format that can be referenced later

tidy_fit.rewarding.object = broom.mixed::tidy(training.data.model.rewarding.object)

# This formats the p-value depending on whether it is less than 0.001. If that is true
# it will just report p < .001 otherwise it will give the exact value rounded to 3 decimal points

formatted_p.rewarding.object = ifelse(tidy_fit.rewarding.object$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste("=", tidy_fit.rewarding.object$p.value %>% round(3))) ## if condition is false
```

Throughout all of training, fish that ate during a session spent on average `r tidy_fit.rewarding.object$estimate[2] %>% round(1)` more seconds near the rewarded object compared to fish that did not eat (Figure, \@ref(fig:training-data-ate-plot), p `r formatted_p.rewarding.object[2]`). Fish that spent more trials eating may therefore have received more reinforcement for the object-food association. 

```{r training-data-ate-plot, echo=FALSE, fig.cap="Preference for the rewarding object during training based on whether an individual ate during a trial or not. Dashed line represents the no preference value. Data are means +/- 95% CI.", fig.id="training-data-ate-plot", warning=FALSE}
###### Time with rewarding object plot during training [gaussian] ######
ggplot(training.data, 
            aes(x = trial, 
                y = rewarding.object.preference, 
                color = ate)) + theme_classic() + geom_jitter(width=0, alpha = 0.5) + stat_summary(
    geom = 'point',
    fun = 'mean',
    size = 4.5,
    shape = 15) +
  stat_summary(geom = 'errorbar', 
               fun.data = 'mean_ci', position = position_dodge(width=0), width = 0.1) + ylab('Rewarding object preference (sec)') + xlab("Trial") + labs(col = "Did this individual eat this trial?") +
  theme(legend.position = "top", axis.text=element_text(size=14), axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5)) + scale_color_manual(values=c("#7f8c8d","#000000")) + 
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line(aes(group = id), alpha = 0.3, arrow = arrow(angle = 30, length = unit(0, "inches"), ends = "first", type = "closed"), lty = 1) 
```


```{r, include = FALSE}
#### Get feeding data #####
# Group by ID and count the number of sessions in which an individual ate 
feeding = my.data %>% group_by(id) %>%  count(feeding.count = ate == 'yes')
feeding
# Remove NAs from this 
feeding = na.omit(feeding)
feeding
# Count only the yeses
feeding = feeding %>% filter(feeding.count == 'TRUE')
# Remove the column session.ate to keep only the counts
feeding = feeding %>% select(-feeding.count)
feeding

# Add the feeding values to the main data frame and replace NAs with 0 
my.feeding.data = left_join(baseline.data, feeding, by ="id")
my.feeding.data = my.feeding.data %>% replace_na(list(n = 0))
my.feeding.data
my.feeding.data = rename(my.feeding.data, feeding.count = n)
my.feeding.data =  my.feeding.data %>% select(id,feeding.count,rewarding.object.colour)
my.feeding.data
```

# Model 5 - Is there a difference in feeding attempts between treatments?

A discrepancy in reinforcement between treatments may influence performance on a final preference test. To see whether there was a difference in feeding between treatments I counted the number of trials in which an individual fish ate throughout all of training and compared the feeding counts between treatments. To do this I fit a generalized linear model with a Poisson distribution. The response variable 'feeding count' is a sum of the number of trials in which a guppy ate.

```{r model 5, echo=TRUE}
feeding.data.model = 
  glm(feeding.count ~ rewarding.object.colour, family = "poisson", 
      data = my.feeding.data)
```



```{r, echo=FALSE, results=FALSE}
# Summary of model 5
tidy_fit.feeding.data.model = broom.mixed::tidy(feeding.data.model)
tidy_fit.feeding.data.model$p.value = ifelse(tidy_fit.feeding.data.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.feeding.data.model$p.value %>% round(3))) ## if condition is false
tidy_fit.feeding.data.model[2:2,]
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.feeding.data.model[2:2,])
```


```{r, include=FALSE}
# Summary of model 5

summary(feeding.data.model)

# This is needed to get the model output in a format that can be referenced later

tidy_fit.feeding.data.model = broom.mixed::tidy(feeding.data.model)

# This formats the p-value depending on whether it is less than 0.001. If that is true
# it will just report p < .001 otherwise it will give the exact value rounded to 3 decimal points

formatted_p.feeding.data.model = ifelse(tidy_fit.feeding.data.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste("=", tidy_fit.feeding.data.model$p.value %>% round(3))) ## if condition is false
```

I found no significant difference in the amount of feeding done by individuals trained to green versus individuals trained to blue (Figure \@ref(fig:feeding-count-plot), p `r formatted_p.feeding.data.model[2]`) which suggests that the observed group-level differences in final test performance between blue-trained guppies versus green-trained guppies  cannot be explained by differences in performance during training.  

```{r feeding-count-plot, echo=FALSE, fig.cap="Average number of trials in which a fish fed during training. Data are means +/- 95% confidence intervals", fig.id="training-data-ate-plot", warning=FALSE}
###### Time with rewarding object plot during training [gaussian] ######
ggplot(my.feeding.data, 
            aes(x = rewarding.object.colour, 
                y = feeding.count, 
                color = rewarding.object.colour)) + theme_classic() + geom_jitter(width=0.1, alpha = 0.8) + stat_summary(
    geom = 'point',
    fun = 'mean',
    size = 4.5,
    shape = 15) +
  stat_summary(geom = 'errorbar', 
               fun.data = 'mean_ci', position = position_dodge(width=0), width = 0.1) + ylab('Number of trials fed') + xlab("Rewarding object colour") + labs(col = "Rewarding object colour") +
  theme(legend.position = "none", axis.text=element_text(size=14), axis.title=element_text(size=14,face="bold"), 
        plot.title = element_text(size=16, hjust=0.5)) + scale_color_manual(values=c("#2980b9", "#27ae60"))
```
 

# Model 6 - What if I control for feeding count?

```{r, include=FALSE}
test.feeding.data = left_join(test.data, feeding, by ="id")
test.feeding.data = test.feeding.data %>% replace_na(list(n = 0))
test.feeding.data = rename(test.feeding.data, feeding.count = n)
retest.feeding.data = test.feeding.data %>% filter(trial == "21")
retest.feeding.data = retest.feeding.data %>% mutate(time.with.both.objects = time.with.trained.object+time.with.untrained.object)
```

```{r, echo = TRUE}
test.data.feeding.controlled.model = 
  lm(rewarding.object.preference ~ trial * rewarding.object.colour + feeding.count, 
     data = test.feeding.data)
```


```{r, echo=FALSE, results=FALSE}
# Summary of model 6
tidy_fit.test.data.feeding.controlled.model = broom.mixed::tidy(test.data.feeding.controlled.model)
tidy_fit.test.data.feeding.controlled.model$p.value = ifelse(tidy_fit.test.data.feeding.controlled.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.test.data.feeding.controlled.model$p.value %>% round(3))) ## if condition is false
tidy_fit.test.data.feeding.controlled.model[2:5,]
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.test.data.feeding.controlled.model[2:5,])
```


Nothing changes if I control for feeding count. The above model is the feeding controlled model. Below we have the non-feeding-count controlled model from earlier.

```{r, echo=FALSE, results=FALSE}
tidy_fit.test.data.model[2:4,] %>% select(-group, -effect)
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.test.data.model[2:4,] %>% select(-group, -effect))
```

In both models the p-values are similar. However the effect of feeding count trends in the expected direction in our feeding count controlled model. In the effect plot below to the left we see that as feeding count increases the preference for the rewarding object colour also increases.

```{r, echo=FALSE, results=TRUE}
plot(allEffects(test.data.feeding.controlled.model))
```


```{r, echo=FALSE, results=FALSE}
## What if I look at just the shift in rewarding object preference frorm baseline to re-test and look for an effect of feeding count. 

test.feeding.data.as.shift.variable = test.feeding.data %>% 
  select(id,trial,rewarding.object.colour,rewarding.object.preference,feeding.count) %>% 
  pivot_wider(names_from = trial, values_from = rewarding.object.preference) %>%
  rename(baseline = "0", retest = "21") %>% 
  mutate(shift.rewarding.object.preference = (retest - baseline))


test.data.feeding.controlled.model2 = 
  lm(shift.rewarding.object.preference ~ feeding.count, 
     data = test.feeding.data.as.shift.variable)

summary(test.data.feeding.controlled.model2)

# Nothing

```

<br />

What if I control for feeding count in just blue guppies. 

```{r, echo=TRUE}
blue.guppies.test.data2 = test.feeding.data %>% filter(rewarding.object.colour == 'blue')
```

```{r, echo=TRUE}
blue.guppies.test.data.model2 = 
  lm(rewarding.object.preference ~ trial + feeding.count,
       data = blue.guppies.test.data2)
```

```{r,results=FALSE,echo=FALSE}
tidy_fit.blue.test.data.model2 = broom.mixed::tidy(blue.guppies.test.data.model2)
tidy_fit.blue.test.data.model2$p.value = ifelse(tidy_fit.blue.test.data.model2$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.blue.test.data.model2$p.value %>% round(3))) ## if condition is false
tidy_fit.blue.test.data.model2
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.blue.test.data.model2)
```


The p-values get smaller compared to when we first look at blue-trained guppies separately without controlling for feeding count but there is still no significant effect. Compare the above with the below to see how the values differ.

```{r, echo=TRUE}
blue.guppies.test.data.model = 
  lm(rewarding.object.preference ~ trial,
       data = blue.guppies.test.data)
```

```{r,results=FALSE,echo=FALSE}
tidy_fit.blue.test.data.model = broom.mixed::tidy(blue.guppies.test.data.model)
tidy_fit.blue.test.data.model$p.value = ifelse(tidy_fit.blue.test.data.model$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.blue.test.data.model$p.value %>% round(3))) ## if condition is false
tidy_fit.blue.test.data.model
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.blue.test.data.model)
```


# Model 7 - Does feeding count predict anything?

** These data are just the final preference trial**

```{r, echo=TRUE}
test.data.feeding.controlled.model1 = 
  lm(rewarding.object.preference ~ feeding.count,
     data = retest.feeding.data)
```

```{r, echo=FALSE, results=FALSE}
# Summary of model 6
tidy_fit.test.data.feeding.controlled.model1 = broom.mixed::tidy(test.data.feeding.controlled.model1)
tidy_fit.test.data.feeding.controlled.model1$p.value = ifelse(tidy_fit.test.data.feeding.controlled.model1$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.test.data.feeding.controlled.model1$p.value %>% round(3))) ## if condition is false
tidy_fit.test.data.feeding.controlled.model1[2:2,]
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.test.data.feeding.controlled.model1[2:2,])
```


Testing for an effect of feeding count on rewarding object preference finds that there is no significant effect but the effect is in the expected direction. 

```{r, echo=FALSE, results=TRUE}
# Summary of model 6
plot(allEffects(test.data.feeding.controlled.model1))
```


However,there is an effect of feeding on the time spent near **both** objects at re-test. 

```{r, echo=TRUE}
test.data.feeding.controlled.model2 = 
  lm(time.with.both.objects ~ feeding.count,
     data = retest.feeding.data)
```

```{r, echo=FALSE, results=FALSE}
# Summary of model 
tidy_fit.test.data.feeding.controlled.model2 = broom.mixed::tidy(test.data.feeding.controlled.model2)
tidy_fit.test.data.feeding.controlled.model2$p.value = ifelse(tidy_fit.test.data.feeding.controlled.model2$p.value < .001, ## Condition
                      "< .001",  ## if condition is true
                      paste(tidy_fit.test.data.feeding.controlled.model2$p.value %>% round(3))) ## if condition is false
tidy_fit.test.data.feeding.controlled.model2[2:2,]
```

```{r, results=TRUE, echo=FALSE}
knitr::kable(tidy_fit.test.data.feeding.controlled.model2[2:2,])

plot((allEffects(test.data.feeding.controlled.model2)))
```


```{r, include=FALSE}
# Summary of model 3
feeding.effect = as.data.frame(allEffects(test.data.feeding.controlled.model2))
```

During the final test, a fish that had `r feeding.effect$feeding.count$feeding.count[1]` feedings spent `r feeding.effect$feeding.count$fit[1] %>% round(3)` seconds near both objects whereas fish that fed in `r feeding.effect$feeding.count$feeding.count[5]` trials spent `r feeding.effect$feeding.count$fit[5] %>% round(3)` seconds near both objects, a `r (feeding.effect$feeding.count$fit[5]/feeding.effect$feeding.count$fit[1]) %>% round(1)`-fold increase.


